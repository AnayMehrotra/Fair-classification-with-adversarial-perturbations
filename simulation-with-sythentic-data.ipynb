{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation on synthetic data (Table 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code form the simulation on the synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# general imports\n",
    "import numpy as np\n",
    "import sys, random\n",
    "import os, warnings\n",
    "import itertools as iter\n",
    "from copy import deepcopy\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "\n",
    "# initialization\n",
    "rng = np.random.default_rng(1234)\n",
    "random.seed()\n",
    "\n",
    "# add to path\n",
    "print(os.getcwd())\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# import ai360\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, CompasDataset\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas\n",
    "\n",
    "# import main code\n",
    "from utils import *\n",
    "import algorithms as denoisedfair\n",
    "from lamy_noise_fairlearn.util import *\n",
    "from awasthi_equalized_odds_under_perturbation.equalized_odds import *\n",
    "\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('baseSimulation.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# RC parameters\n",
    "from matplotlib import rc, rcParams\n",
    "\n",
    "rcParams.update({\n",
    "        'text.usetex': False,\n",
    "        'font.family': 'stixgeneral',\n",
    "        'mathtext.fontset': 'stix',\n",
    "        'figure.figsize': (10,6),\n",
    "})\n",
    "\n",
    "import datetime\n",
    "import string\n",
    "\n",
    "home_folder = '.'\n",
    "\n",
    "def file_str():\n",
    "    \"\"\" Auto-generates file name.\"\"\"\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"H%HM%MS%S_%m-%d-%y\")\n",
    "\n",
    "rand_string = lambda length: ''.join(random.choice(string.ascii_lowercase) for i in range(length))\n",
    "\n",
    "def pdf_savefig():\n",
    "    \"\"\" Saves figures as pdf \"\"\"\n",
    "    fname = file_str()+rand_string(20)\n",
    "    plt.savefig(home_folder+f\"/figs/{fname}.pdf\")\n",
    "\n",
    "def eps_savefig():\n",
    "    \"\"\" Saves figure as encapsulated postscript file (vector format)\n",
    "        so that it isn't pixelated when we put it into a pdf. \"\"\"\n",
    "    pdf_savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to generate adversarial noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     6,
     12,
     18
    ]
   },
   "outputs": [],
   "source": [
    "flipping_far_from_boundary = lambda feature_names, features, labels,\\\n",
    "                                        name, eta0, eta1: \\\n",
    "                                                    flipping_syn_far_from_boundary(feature_names,\\\n",
    "                                                    features, labels, name, eta0, eta1, pred_lab=0,\n",
    "                                                    rng_loc=None, in_use_prot_attr = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def gen_syn_data(n):\n",
    "    data = []\n",
    "    labels = []\n",
    "    zer = np.random.normal(0,0.2,20*n)\n",
    "    one = np.random.normal(1,0.2,20*n)\n",
    "    #\n",
    "    label = np.random.rand(20*n)\n",
    "    #\n",
    "    z=0\n",
    "    o=0\n",
    "    #\n",
    "    sft = -0.5 # shift (to center at 0)\n",
    "    # generate samples for z=1\n",
    "    for i in range(int(0.333*n//4)): data.append([1, zer[o], 1+one[o+1]+sft]); labels.append([1]); o+=2\n",
    "    for i in range(int(0.555*n//4)): data.append([1, zer[o], one[o+1]+sft]); labels.append([1]); o+=2\n",
    "    for i in range(int(0.222*n//4)): data.append([1, zer[o], zer[o+1]+sft]); labels.append([0]); o+=2\n",
    "    for i in range(int(0.888*n//4)): data.append([1, zer[o], -one[o+1]+sft]); labels.append([0]); o+=2\n",
    "    # generate samples for z=2\n",
    "    for i in range(int(0.888*n//4)): data.append([0, zer[o], 1+one[o+1]+sft]); labels.append([1]); o+=2\n",
    "    for i in range(int(0.222*n//4)): data.append([0, zer[o], one[o+1]+sft]); labels.append([1]); o+=2\n",
    "    for i in range(int(0.555*n//4)): data.append([0, zer[o], zer[o+1]+sft]); labels.append([0]); o+=2\n",
    "    for i in range(int(0.333*n//4)): data.append([0, zer[o], -one[o+1]+sft]); labels.append([0]); o+=2\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('mkdir figs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5,
     11,
     13
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = 6000\n",
    "syn_data, syn_labels = gen_syn_data(N)\n",
    "\n",
    "indMpos, indMneg, indFpos, indFneg = [], [], [], []\n",
    "\n",
    "for i in range(len(syn_labels)):\n",
    "    if syn_data[i][0] == 0 and syn_labels[i] == 1: indMpos.append(i)\n",
    "    if syn_data[i][0] == 0 and syn_labels[i] == 0: indMneg.append(i)\n",
    "    if syn_data[i][0] == 1 and syn_labels[i] == 1: indFpos.append(i)\n",
    "    if syn_data[i][0] == 1 and syn_labels[i] == 0: indFneg.append(i)\n",
    "        \n",
    "        \n",
    "##############################################################################\n",
    "########################## Plot for Z=1 ######################################\n",
    "##############################################################################\n",
    "plt.scatter(syn_data[:,1][indMpos], syn_data[:,2][indMpos], marker='+', alpha=0.5,\\\n",
    "            color='blue', label='Positive samples', linewidth=2)\n",
    "plt.scatter(syn_data[:,1][indMneg], syn_data[:,2][indMneg], marker='_', alpha=0.5,\\\n",
    "            color='red', label='Negative samples', linewidth=2)\n",
    "\n",
    "plt.ylim(-2,2)\n",
    "plt.xlim(-1,1)\n",
    "plt.xlabel('Feature 2', fontsize=25)\n",
    "plt.ylabel('Feature 1', fontsize=25)\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "legend = plt.legend(shadow=False, fontsize=20, bbox_to_anchor=(0.51, 0.3, 0.9, .102))\n",
    "\n",
    "plt.title(f'Synthetic dataset: Samples with $Z=1$', fontsize=25)\n",
    "\n",
    "\n",
    "pdf_savefig()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "########################## Plot for Z=2 ######################################\n",
    "##############################################################################\n",
    "plt.scatter(syn_data[:,1][indFpos], syn_data[:,2][indFpos], marker='+', alpha=0.5,\\\n",
    "            color='blue', label='Positive samples', linewidth=2)\n",
    "plt.scatter(syn_data[:,1][indFneg], syn_data[:,2][indFneg], marker='_', alpha=0.5,\\\n",
    "            color='red', label='Negative samples', linewidth=2)\n",
    "\n",
    "plt.ylim(-2,2)\n",
    "plt.xlim(-1,1)\n",
    "plt.xlabel('Feature 2', fontsize=25)\n",
    "plt.ylabel('Feature 1', fontsize=25)\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "legend = plt.legend(shadow=False, fontsize=20, bbox_to_anchor=(0.51, 0.3, 0.9, .102))\n",
    "\n",
    "plt.title(f'Synthetic dataset: Samples of with $Z=2$', fontsize=25)\n",
    "\n",
    "pdf_savefig()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "ITERS = 100\n",
    "CORES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     23,
     67,
     69
    ]
   },
   "outputs": [],
   "source": [
    "def gen_data(eta=[0,0],flip_func=flipping_far_from_boundary, N=1000):\n",
    "    syn_data, syn_labels = gen_syn_data(int(N*0.7))\n",
    "    syn_data_test, syn_labels_test = gen_syn_data(int(N*0.3))\n",
    "    \n",
    "    def shuffle(a,b):\n",
    "        assert len(a) == len(b)\n",
    "        ind = np.array([i for i in range(len(a))])\n",
    "        random.shuffle(ind)\n",
    "        return a[ind], b[ind]\n",
    "    \n",
    "    syn_data, syn_labels = shuffle(syn_data, syn_labels)\n",
    "    \n",
    "    index, syn_data_gen_noisy = flip_func([\"gender\", \"x\", \"y\"], syn_data, syn_labels, \"gender\", eta[0], eta[1])\n",
    "    syn_data_noisy = copy.deepcopy(syn_data)\n",
    "    syn_data_noisy[:, 0] = syn_data_gen_noisy\n",
    "    \n",
    "    return syn_data, syn_labels, syn_data_noisy, index, syn_data_test, syn_labels_test\n",
    "\n",
    "def denoised_theta_with_perturbations(eta = [0, 0.05], tau=0.9, flip_func = flipping_far_from_boundary):\n",
    "    #### initialize\n",
    "    C=0\n",
    "    lam=1/6 # accurate value of lambda on the distribution from which we draw the data\n",
    "    delta=0.01\n",
    "    rng_loc = rng\n",
    "    np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "    \n",
    "    H = np.array([[1-eta[0], eta[0]], [eta[1], 1-eta[1]]])\n",
    "    \n",
    "    acc = []; sr = []; fpr = []; tpr = []\n",
    "\n",
    "    def select_job(job_id, ss):\n",
    "        np.random.seed(job_id)\n",
    "        if ss is not None: rng_loc = np.random.default_rng(ss)\n",
    "        else: rng_loc = rng\n",
    "        #\n",
    "        #########################################\n",
    "        #### load noisy data with imputed PA\n",
    "        #########################################\n",
    "        syn_data, syn_labels, syn_data_noisy, index,\\\n",
    "                     syn_data_test, syn_labels_test    = gen_data(eta, flip_func=flip_func)\n",
    "        #\n",
    "        denoised_theta = denoisedfair.denoised(syn_data_noisy, syn_labels, index, C, tau, H, \"sr\", lam=lam, delta=3*delta, in_use_prot_attr=False)\n",
    "        if verbose: print('\\n'*2)\n",
    "        if verbose: print(f\"THETA: {denoised_theta}\")\n",
    "        if verbose: print(\"test on true:\", testing(syn_data, syn_data[:,index], syn_labels, index, denoised_theta))\n",
    "        res = testing(syn_data_test, syn_data_test[:,index], syn_labels_test, index, denoised_theta)\n",
    "            \n",
    "            \n",
    "        return res\n",
    "        \n",
    "    ss = rng.bit_generator._seed_seq ## seed sequence (source: https://albertcthomas.github.io/good-practices-random-number-generators/)\n",
    "    child_states = ss.spawn(ITERS) ## child sequences\n",
    "    answer = Parallel(n_jobs=CORES, verbose=100)(delayed(select_job)(int(i), child_states[i]) for i in range(ITERS))\n",
    "    \n",
    "    all_results = {}\n",
    "    for i in range(ITERS):\n",
    "        acc.append(answer[i]['acc'])\n",
    "        sr.append(answer[i]['sr'])\n",
    "        fpr.append(answer[i]['fpr'])\n",
    "        tpr.append(answer[i]['tpr'])\n",
    "\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'\\tacc\\tsr\\tfpr')\n",
    "        print(f'Means:\\t{np.round(np.mean(acc),3)}\\t{np.round(np.mean(sr),3)}\\t{np.round(np.mean(fpr),3)}')\n",
    "        print(f'Std:\\t{np.round(np.std(acc),3)}\\t{np.round(np.std(sr),3)}\\t{np.round(np.std(fpr),3)}')\n",
    "        print('')\n",
    "        print(f'Acc: {acc}')\n",
    "        print(f'Sr: {sr}')\n",
    "        print(f'Fpr: {fpr}')\n",
    "        print(f'tpr: {tpr}')\n",
    "    return acc, sr, fpr, tpr\n",
    "\n",
    "def err_tolerant_theta_with_perturbations(eta = [0, 0.05], tau=0.9, flip_func = flipping_far_from_boundary):\n",
    "    from scipy.optimize import minimize\n",
    "    def computeWorstRate(a, b, c, d, eta=0):\n",
    "        # (a-\\eta_1)/(a+b-\\eta_1+\\eta_2) * (c+d+\\eta_1-\\eta_2)/(c+\\eta_1)\n",
    "\n",
    "        def obj(x):\n",
    "            return (a-x[0]) * (c+d+x[0]-x[1]) / (a+b-x[0]+x[1]) / (c+x[0])\n",
    "\n",
    "        def der(x):\n",
    "            der0  = 0\n",
    "            der0 += (a-x[0]) / (c+x[0]) / (a+b-x[0]+x[1])\n",
    "            der0 += (a-x[0]) * (c+d+x[0]-x[1]) / (c+x[0]) / (a+b-x[0]+x[1])**2\n",
    "            der0 -= (c+d+x[0]-x[1]) / (c+x[0]) / (a+b-x[0]+x[1])\n",
    "            der0 -= (a-x[0]) * (c+d+x[0]-x[1]) / (c+x[0]) ** 2 / (a+b-x[0]+x[1])\n",
    "            #\n",
    "            der1  = 0\n",
    "            der1 -= (a-x[0]) / (c+x[0]) / (a+b-x[0]+x[1])\n",
    "            der1 -= (a-x[0]) * (c+d+x[0]-x[1]) / (c+x[0]) / (a+b-x[0]+x[1])**2\n",
    "            #\n",
    "            return np.array([der0, der1])\n",
    "\n",
    "        def const(x):\n",
    "            f = []\n",
    "            f.append(eta - x[0] - x[1])\n",
    "            f.append(eta - x[0])\n",
    "            f.append(eta - x[1])\n",
    "            f.append(c - x[0])\n",
    "            f.append(b - x[1])\n",
    "            f.append(x[0])\n",
    "            f.append(x[1])\n",
    "            return f\n",
    "\n",
    "        res = {'success': False}\n",
    "        mn = 1000\n",
    "\n",
    "        for i in range(10):\n",
    "            # initialize random solution\n",
    "            x0 = np.random.rand(2)\n",
    "            x0 *= eta / np.sum(x0)\n",
    "\n",
    "            # initialize constraints\n",
    "            ineq_cons = {'type': 'ineq', 'fun' : lambda x: const(x)}\n",
    "\n",
    "            # solve problem\n",
    "            res = minimize(fun = obj, x0 = x0, method='SLSQP', jac = der, constraints = [ineq_cons],\\\n",
    "                     options = {'maxiter': 100, 'ftol': 1e-6, 'eps' : 1e-6, 'disp': False})\n",
    "\n",
    "            cst = const(res.x)\n",
    "\n",
    "            if np.min(cst) < -1e-2:\n",
    "                print(f\"Solution violates the constraints!\\nconstraints: {const}\")\n",
    "                continue\n",
    "\n",
    "            mn = min(mn, obj(res.x) / obj(np.zeros(2)))\n",
    "\n",
    "        return mn\n",
    "    \n",
    "    #########################################\n",
    "    #### initialize\n",
    "    #########################################\n",
    "    C=0\n",
    "    delta=0.01\n",
    "    rng_loc = rng\n",
    "    np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "    \n",
    "\n",
    "    acc = []; sr = []; fpr = []; tpr = []\n",
    "\n",
    "    for i in range(ITERS):\n",
    "        #########################################\n",
    "        #### load noisy data with imputed PA\n",
    "        #########################################\n",
    "        syn_data, syn_labels, syn_data_noisy, index,\\\n",
    "                     syn_data_test, syn_labels_test    = gen_data(eta, flip_func=flip_func)\n",
    "        \n",
    "        p0 = 0.5 \n",
    "        p1 = 0.5 \n",
    "        p00 = np.mean((syn_data_noisy[:, index] == 0) & (syn_labels == 0)) # 1/3\n",
    "        p10 = np.mean((syn_data_noisy[:, index] == 1) & (syn_labels == 0)) # 1/6\n",
    "        p01 = np.mean((syn_data_noisy[:, index] == 0) & (syn_labels == 1)) # 1/3\n",
    "        p11 = np.mean((syn_data_noisy[:, index] == 1) & (syn_labels == 1)) # 1/6\n",
    "\n",
    "        eta_avg = eta[0] * p0 + eta[1] * p1    \n",
    "        tauRelaxed = tau * computeWorstRate(p01, p00, p11, p10, eta_avg)\n",
    "        tauRelaxed = min(tauRelaxed, tau * computeWorstRate(p11, p10, p01, p00, eta_avg)) \n",
    "        lamRelaxed = min(p01, p11) - eta_avg - 3*delta\n",
    "        \n",
    "        print(f'lamRelaxed: {lamRelaxed}, tauRelaxed: {tauRelaxed}.')\n",
    "        \n",
    "        \n",
    "        if verbose: print(f'Error-tolerant classifier for tau={tau}: ')\n",
    "        err_tolerant_theta = denoisedfair.undenoised_lambda(syn_data_noisy, syn_labels, index, C, tauRelaxed, \"sr\", delta=0.00, lam=lamRelaxed)\n",
    "        \n",
    "        res = testing(syn_data_test, syn_data_test[:,index], syn_labels_test, index, err_tolerant_theta)\n",
    "        \n",
    "        acc.append(res['acc'])\n",
    "        sr.append(res['sr'])\n",
    "        fpr.append(res['fpr'])\n",
    "        tpr.append(res['tpr'])\n",
    "        if verbose: print('\\n'*2)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'\\tacc\\tsr\\tfpr\\t')\n",
    "        print(f'Means:\\t{np.round(np.mean(acc),3)}\\t{np.round(np.mean(sr),3)}\\t{np.round(np.mean(fpr),3)}\\t{np.round(np.mean(tpr),3)}')\n",
    "        print(f'Std:\\t{np.round(np.std(acc),3)}\\t{np.round(np.std(sr),3)}\\t{np.round(np.std(fpr),3)}\\t{np.round(np.std(tpr),3)}')\n",
    "        print('')\n",
    "        print(f'Acc: {acc}')\n",
    "        print(f'Sr: {sr}')\n",
    "        print(f'Fpr: {fpr}')\n",
    "        print(f'Fpr: {tpr}')\n",
    "    return acc, sr, fpr, tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ErrTol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def run_err_tol(tau=0.8):\n",
    "    output = ''\n",
    "    for e in [0.0,0.03,0.05]:\n",
    "        acc, sr, fpr, tpr = err_tolerant_theta_with_perturbations(eta = [0, e], tau=tau,\\\n",
    "                                                         flip_func = flipping_far_from_boundary)\n",
    "\n",
    "        output += f'Eta=[0,{e}]'\n",
    "        output += '\\n'\n",
    "        output += f'\\tacc\\tsr\\tfpr\\ttpr'\n",
    "        output += '\\n'\n",
    "        output += f'Means:\\t{np.round(np.mean(acc),3)}\\t{np.round(np.mean(sr),3)}\\t{np.round(np.mean(fpr),3)}\\t{np.round(np.mean(tpr),3)}'\n",
    "        output += '\\n'\n",
    "        output += f'Std:\\t{np.round(np.std(acc),3)}\\t{np.round(np.std(sr),3)}\\t{np.round(np.std(fpr),3)}\\t{np.round(np.std(tpr),3)}'\n",
    "        output += '\\n'\n",
    "        output += '\\n'\n",
    "\n",
    "    print('\\n'*5)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_err_tol(tau=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHKV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def run_denoised(tau=0.8):\n",
    "    output = ''\n",
    "    for e in tqdm([0.0,0.03,0.05]):\n",
    "        acc, sr, fpr, tpr = denoised_theta_with_perturbations(eta = [e, 0], tau=tau,\\\n",
    "                                                         flip_func = flipping_far_from_boundary)\n",
    "\n",
    "        output += f'Eta=[0,{e}]'\n",
    "        output += '\\n'\n",
    "        output += f'\\tacc\\tsr\\tfpr\\ttpr'\n",
    "        output += '\\n'\n",
    "        output += f'Means:\\t{np.round(np.mean(acc),3)}\\t{np.round(np.mean(sr),3)}\\t{np.round(np.mean(fpr),3)}\\t{np.round(np.mean(tpr),3)}'\n",
    "        output += '\\n'\n",
    "        output += f'Std:\\t{np.round(np.std(acc),3)}\\t{np.round(np.std(sr),3)}\\t{np.round(np.std(fpr),3)}\\t{np.round(np.std(tpr),3)}'\n",
    "        output += '\\n'\n",
    "        output += '\\n'\n",
    "\n",
    "    print('\\n'*5)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_denoised(tau=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unconstrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_denoised(tau=0.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
