{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of WGN+SW for simulation with adversarial perturbations (Figure 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides the implementation of Wang et al. 2020 paper for our settings and datasets - most of the code is the same as the official implementation - https://github.com/wenshuoguo/robust-fairness-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# general imports\n",
    "import numpy as np\n",
    "import sys, random\n",
    "import os, warnings\n",
    "import itertools as iter\n",
    "from copy import deepcopy\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "\n",
    "# initialization\n",
    "rng = np.random.default_rng(8735) #(1234)\n",
    "random.seed()\n",
    "\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "# add to path\n",
    "print(os.getcwd())\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# import ai360\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, CompasDataset\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas\n",
    "\n",
    "# import main code\n",
    "from utils import *\n",
    "import algorithms as denoisedfair\n",
    "from lamy_noise_fairlearn.util import *\n",
    "from awasthi_equalized_odds_under_perturbation.equalized_odds import *\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "sys.path.append(os.getcwd()+'/robust-fairness-code/')\n",
    "from softweights_training import *\n",
    "import dro_training, naive_training, data, losses, optimization, model, rbc_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('baseSimulation.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder = 'results'\n",
    "os.system(f'mkdir {result_folder}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def test_sw_flipping_parallel(eta0=0.3, eta1=0.1, flip_func = flipping, d='compas', reps=100):\n",
    "    results_dicts_runs = []  \n",
    "    \n",
    "    constraint = 'fpr'\n",
    "    learning_rates_theta = [0.001, 0.01, 0.1]\n",
    "    learning_rates_lambda = [0.5, 1.0, 2.0]\n",
    "    learning_rates_W =   [0.01, 0.1]\n",
    "    num_runs=1\n",
    "    minibatch_size=None\n",
    "    num_iterations_per_loop= 25\n",
    "    num_loops= 30\n",
    "    constraints_slack=0.0\n",
    "    num_avg_iters=0\n",
    "    optimize_robust_constraints=False\n",
    "    rank_objectives=False # parameters for find_best_candidate_index\n",
    "    max_constraints=False # parameters for find_best_candidate_index\n",
    "    num_iterations_W=5\n",
    "    max_diff=0.05 #0.01\n",
    "    best_index_nburn=0 # Number of initial candidate indices to exclude from find_best_candidate_index.\n",
    "    seed_start=100\n",
    "\n",
    "    def select_job(job_id, ss):\n",
    "        np.random.seed(job_id+1234)\n",
    "        \n",
    "        if ss==None: rng_loc = rng\n",
    "        else: rng_loc = np.random.default_rng(ss)\n",
    "        \n",
    "        attr = \"sex\"\n",
    "        if d == \"compas\": dataset = load_preproc_data_compas()\n",
    "        else: raise NotImplementedError\n",
    "\n",
    "        protected_name = attr\n",
    "\n",
    "        dataset_train, dataset_test = dataset.split([0.7], shuffle=True)\n",
    "        train_labels = [1-int(lab[0]) for lab in dataset_train.labels]\n",
    "        test_labels = [1-int(lab[0]) for lab in dataset_test.labels]\n",
    "\n",
    "        index, noisyfea, eta_group = flip_func(dataset_train.feature_names, dataset_train.features, train_labels, protected_name, eta0, eta1, rng)\n",
    "        index, test_noisyfea, _ = flip_func(dataset_test.feature_names, dataset_test.features, test_labels, protected_name, eta0, eta1, rng)\n",
    "        \n",
    "        print(f'ETAgroup {eta_group}')\n",
    "\n",
    "        feature_names = dataset_train.feature_names\n",
    "        del(feature_names[index])\n",
    "        feature_names = feature_names + [\"attr_1\", \"attr_2\"] + [\"proxy_1\", \"proxy_2\"]\n",
    "\n",
    "        train_groups = list(dataset_train.features[:,index])\n",
    "        test_groups = list(dataset_test.features[:,index])\n",
    "\n",
    "        dataset_train = dataset_train.features \n",
    "        dataset_train = np.delete(dataset_train, index, 1)\n",
    "        dataset_test = dataset_test.features\n",
    "        dataset_test = np.delete(dataset_test, index, 1)\n",
    "\n",
    "        feat_n = [[1] if train_groups[i] == 1 else [0] for i in range(len(train_groups))]\n",
    "        feat_a = [[1] if train_groups[i] == 0 else [0] for i in range(len(train_groups))]\n",
    "\n",
    "        dataset_train = np.hstack((dataset_train, feat_n))\n",
    "        dataset_train = np.hstack((dataset_train, feat_a))\n",
    "\n",
    "        dataset_noisy = np.copy(dataset_train)\n",
    "\n",
    "        feat_n = [[1] if noisyfea[i] == 1 else [0] for i in range(len(noisyfea))]\n",
    "        feat_a = [[1] if noisyfea[i] == 0 else [0] for i in range(len(noisyfea))]\n",
    "        dataset_noisy = np.hstack((dataset_noisy, feat_n))\n",
    "        dataset_noisy = np.hstack((dataset_noisy, feat_a))\n",
    "\n",
    "        feat_n = [[1] if test_groups[i] == 1 else [0] for i in range(len(test_groups))]\n",
    "        feat_a = [[1] if test_groups[i] == 0 else [0] for i in range(len(test_groups))]\n",
    "\n",
    "        dataset_test = np.hstack((dataset_test, feat_n))\n",
    "        dataset_test = np.hstack((dataset_test, feat_a))\n",
    "\n",
    "        dataset_noisy_test = np.copy(dataset_test)\n",
    "        feat_n = [[1] if test_noisyfea[i] == 1 else [0] for i in range(len(test_noisyfea))]\n",
    "        feat_a = [[1] if test_noisyfea[i] == 0 else [0] for i in range(len(test_noisyfea))]\n",
    "        dataset_noisy_test = np.hstack((dataset_noisy_test, feat_n))\n",
    "        dataset_noisy_test = np.hstack((dataset_noisy_test, feat_a))\n",
    "\n",
    "        dataset_train_pd = pd.DataFrame(dataset_noisy, columns=feature_names)\n",
    "        dataset_train_pd['label'] = train_labels\n",
    "        train_df = dataset_train_pd.copy()\n",
    "\n",
    "        dataset_test_pd = pd.DataFrame(dataset_noisy_test, columns=feature_names)\n",
    "        dataset_test_pd['label'] = test_labels\n",
    "        test_df = dataset_test_pd.copy()\n",
    "\n",
    "        val_df = train_df.copy()\n",
    "\n",
    "        label_column = \"label\" \n",
    "        feature_names = list(dataset_train_pd.columns)\n",
    "        feature_names.remove(label_column)\n",
    "        protected_columns = [\"attr_1\", \"attr_2\"]\n",
    "\n",
    "        proxy_columns = [\"proxy_1\", \"proxy_2\"]\n",
    "        b = build_b(train_df, proxy_columns, protected_columns)\n",
    "        true_group_marginals = get_true_group_marginals(train_df, protected_columns)\n",
    "\n",
    "        val_objectives = []\n",
    "        val_constraints_matrix = []\n",
    "        results_dicts = []\n",
    "        learning_rates_iters_theta = []\n",
    "        learning_rates_iters_lambda = []\n",
    "        learning_rates_iters_W = []\n",
    "\n",
    "        results = []\n",
    "        results_train = []\n",
    "        result_details = []\n",
    "        \n",
    "        bar = tqdm(itertools.product(learning_rates_theta, learning_rates_lambda, learning_rates_W))\n",
    "        for learning_rate_theta, learning_rate_lambda, learning_rate_W in bar:\n",
    "            bar.set_description(\"Starting optimizing LR theta: %.3f, LR lambda: %.3f, LR W: %.3f\" % (learning_rate_theta, learning_rate_lambda, learning_rate_W))\n",
    "            bar.refresh() # to show immediately the update\n",
    "            sw_model = SoftweightsHeuristicModel(b, true_group_marginals, feature_names, proxy_columns, label_column, maximum_lambda_radius=1.0)\n",
    "            sw_model.build_train_ops(constraint=constraint, learning_rate_theta=learning_rate_theta, learning_rate_lambda=learning_rate_lambda, learning_rate_W=learning_rate_W, constraints_slack=constraints_slack)\n",
    "\n",
    "            # training_helper returns the list of errors and violations over each epoch.\n",
    "            results_dict = training_helper(\n",
    "                  sw_model,\n",
    "                  train_df,\n",
    "                  val_df,\n",
    "                  test_df,\n",
    "                  protected_columns, \n",
    "                  proxy_columns, \n",
    "                  label_column,\n",
    "                  minibatch_size=minibatch_size,\n",
    "                  num_iterations_per_loop=num_iterations_per_loop,\n",
    "                  num_loops=num_loops,\n",
    "                  optimize_robust_constraints=optimize_robust_constraints,\n",
    "                  num_iterations_W=num_iterations_W,\n",
    "                  max_diff=max_diff,\n",
    "                  constraint=constraint)\n",
    "\n",
    "            \n",
    "            # Get best iterate using training set.\n",
    "            best_index_iters = rbc_utils.find_best_candidate_index(np.array(results_dict['train_01_objective_vector'][best_index_nburn:]),np.array(results_dict['train_01_robust_constraints_matrix'][best_index_nburn:]), rank_objectives=rank_objectives, max_constraints=max_constraints)\n",
    "            best_index_iters = best_index_iters + best_index_nburn\n",
    "            results_dict_best_idx = add_results_dict_best_idx(results_dict, best_index_iters)\n",
    "            results_dicts.append(results_dict_best_idx)\n",
    "            if num_avg_iters == 0:\n",
    "                best_val_objective = results_dict['val_01_objective_vector'][best_index_iters]\n",
    "                best_val_constraints = results_dict['val_01_true_G_constraints_matrix'][best_index_iters]\n",
    "                val_objectives.append(best_val_objective)\n",
    "                val_constraints_matrix.append(best_val_constraints)\n",
    "                \n",
    "                stats = results_dict['stat_test_vector'][best_index_iters]\n",
    "                stats_train = results_dict['stat_train_vector'][best_index_iters]\n",
    "                results.append(stats)\n",
    "                results_train.append(stats_train)\n",
    "                print(f'outside stats: {results_train}')\n",
    "            else: \n",
    "                assert(num_avg_iters > 0)\n",
    "                avg_val_objective = np.mean(np.array(results_dict['val_01_objective_vector'][-num_avg_iters:]))\n",
    "                val_objectives.append(avg_val_objective)\n",
    "                avg_val_constraints = np.mean(np.array(results_dict['val_01_robust_constraints_matrix'][-num_avg_iters:]), axis=0)\n",
    "                val_constraints_matrix.append(avg_val_constraints)\n",
    "            \n",
    "            learning_rates_iters_theta.append(learning_rate_theta)\n",
    "            learning_rates_iters_lambda.append(learning_rate_lambda)\n",
    "            learning_rates_iters_W.append(learning_rate_W)\n",
    "            \n",
    "            result_details.append(results_dict)\n",
    "\n",
    "        best_index = rbc_utils.find_best_candidate_index(np.array(val_objectives),\\\n",
    "                                                         np.array(val_constraints_matrix),\\\n",
    "                                                         rank_objectives=rank_objectives,\\\n",
    "                                                         max_constraints=max_constraints)\n",
    "        best_stats = results[best_index]\n",
    "        best_stats_train = results_train[best_index]\n",
    "        best_learning_rate_theta = learning_rates_iters_theta[best_index]\n",
    "        best_learning_rate_lambda = learning_rates_iters_lambda[best_index]\n",
    "        best_learning_rate_W = learning_rates_iters_W[best_index]\n",
    "            \n",
    "        print(f'Result one rep: {best_stats} @ θ:{best_learning_rate_theta} λ:{best_learning_rate_lambda} W:{best_learning_rate_W}')\n",
    "        print(f'Result one rep train: {best_stats_train}')\n",
    "        \n",
    "        return results, results_train, result_details, best_stats\n",
    "        \n",
    "    # reps = 100\n",
    "    all_results = []\n",
    "    all_results_train = []\n",
    "    all_result_details = []\n",
    "    all_best_stats = []\n",
    "    \n",
    "    CORES = 10\n",
    "    \n",
    "    ss = rng.bit_generator._seed_seq ## seed sequence (source: https://albertcthomas.github.io/good-practices-random-number-g\n",
    "    child_states = ss.spawn(reps) ## child sequences\n",
    "    \n",
    "    answer = Parallel(n_jobs=CORES, verbose=100)(delayed(select_job)(int(i), child_states[i]) for i in range(reps))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(reps):\n",
    "        all_results.append(answer[i][0])\n",
    "        all_results_train.append(answer[i][1])\n",
    "        all_result_details.append(answer[i][2])\n",
    "        all_best_stats.append(answer[i][3])\n",
    "    \n",
    "    \n",
    "    acc = []; sr = []; fpr = []; fdr = []; tpr = [];\n",
    "    for t in all_best_stats: \n",
    "        if t['sr']==0: continue\n",
    "        acc.append(t['acc']); sr.append(t['sr']); fpr.append(t['fpr']); \n",
    "        fdr.append(t['fdr']); tpr.append(t['tpr']); \n",
    "\n",
    "    print('')\n",
    "    print('')\n",
    "    \n",
    "    print(all_best_stats)\n",
    "    \n",
    "    print('')\n",
    "    print('')\n",
    "    \n",
    "    print(f\"Results: acc={np.mean(acc)} std={np.std(acc)}\")\n",
    "    print(f\"\\tSR={np.mean(sr)} std={np.std(sr)}\")\n",
    "    print(f\"\\tFPR={np.mean(fpr)} std={np.std(fpr)}\")\n",
    "    print(f\"\\tFDR={np.mean(fdr)} std={np.std(fdr)}\")\n",
    "    print(f\"\\tTPR={np.mean(tpr)} std={np.std(tpr)}\")\n",
    "    \n",
    "    \n",
    "    f = open(f'{result_folder}/WGN+SW-internal', 'wb')\n",
    "    pickle.dump(all_results, f)\n",
    "    f = open(f'{result_folder}/WGN+SW-internal-train', 'wb')\n",
    "    pickle.dump(all_results_train, f)\n",
    "    f = open(f'{result_folder}/WGN+SW-internal-details', 'wb')\n",
    "    pickle.dump(all_result_details, f)\n",
    "    \n",
    "    return all_results, all_results_train, all_result_details, all_best_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnning simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversary: A_TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "all_results, all_results_train, all_result_details, all_best_stats = test_sw_flipping_parallel(eta0=0.0175,\\\n",
    "                                                                                               eta1=0.0,\\\n",
    "                                                                                               flip_func=flipping_far_from_boundary_TN,\\\n",
    "                                                                                               reps=reps)\n",
    "print(f'Time taken: {time.time() - st}')\n",
    "\n",
    "f = open(f'{result_folder}/WGN+SW-TN-{reps}iters', 'wb')\n",
    "pickle.dump(all_results, f)\n",
    "f = open(f'{result_folder}/WGN+SW-TN-{reps}iters-train', 'wb')\n",
    "pickle.dump(all_results_train, f)\n",
    "f = open(f'{result_folder}/WGN+SW-TN-{reps}iters-details', 'wb')\n",
    "pickle.dump(all_result_details, f)\n",
    "f = open(f'{result_folder}/WGN+SW-TN-{reps}iters-best', 'wb')\n",
    "pickle.dump(all_best_stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversary: A_FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "all_results, all_results_train, all_result_details, all_best_stats = test_sw_flipping_parallel(eta0=0.0175, \\\n",
    "                                                                                               eta1=0.0,\\\n",
    "                                                                                               flip_func=flipping_far_from_boundary_FN,\\\n",
    "                                                                                               reps=reps)\n",
    "print(f'Time taken: {time.time() - st}')\n",
    "\n",
    "f = open(f'{result_folder}/WGN+SW-FN-{reps}iters', 'wb')\n",
    "pickle.dump(all_results, f)\n",
    "f = open(f'{result_folder}/WGN+SW-FN-{reps}iters-train', 'wb')\n",
    "pickle.dump(all_results_train, f)\n",
    "f = open(f'{result_folder}/WGN+SW-FN-{reps}iters-details', 'wb')\n",
    "pickle.dump(all_result_details, f)\n",
    "f = open(f'{result_folder}/WGN+SW-FN-{reps}iters-best', 'wb')\n",
    "pickle.dump(all_best_stats, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
